{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ba2387-54e8-4aa5-aedb-c7d90644536f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img src=\"https://logos-world.net/wp-content/uploads/2020/05/NASA-Logo-1959-present.png\" width=\"100px\" align=\"middle\" /> NASA Earthdata API Client 🌍\n",
    "\n",
    "## Overview\n",
    "\n",
    "#### TL;DR: [**earthdata**](https://github.com/nsidc/earthdata) is a Python package to search, preview and access NASA datasets (on-prem or in the cloud) with a few lines of code.\n",
    "\n",
    "```python\n",
    "\n",
    "from earthdata import Auth, DataGranules, Store\n",
    "\n",
    "# first we authenticate with NASA EDL\n",
    "auth = Auth().login(strategy=\"netrc\")\n",
    "\n",
    "# Then we build a Query with spatiotemporal parameters\n",
    "GranuleQuery = DataGranules().concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "\n",
    "# We get the metadata records from CMR\n",
    "granules = GranuleQuery.get()\n",
    "\n",
    "# Now it{s time to download (or open) our data granules list with get()\n",
    "files = Store(auth).get(granules, local_path='./data')\n",
    "\n",
    "# Now to the important science!\n",
    "```\n",
    "\n",
    "\n",
    "### Why use the `earthdata` Python package?\n",
    "\n",
    "There are many ways to access NASA datasets, we can use the [Earthdata search portal](https://search.earthdata.nasa.gov/). We can use DAAC specific portals or tools.\n",
    "We could even use [data.gov](https://data.gov)!  Web portals are great but they are not designed for programmatic access and reproducible workflows. This is extremely important in the age of the cloud and reproducible open science. \n",
    "\n",
    "The good news is that NASA also exposes APIs that allows us to search, transform and access data in a programmatic way. Many of these libraries contain amazing features and some similarities. In this context, **earthdata** aims to be a simple library that can deal with the important parts of the metadata so we can access or download data without having to worry if a given dataset is on-prem or in the cloud.\n",
    "\n",
    "\n",
    "Library | Language Agnostic | On-Prem Access | Cloud Access | Programmatic | Subsetting | GIS Operations | Authentication | Full Archive Coverage|\n",
    "-------- | ----- | -------- | ----- | -------- | ----- | -------- | ----- | -----\n",
    "**earthdata** | Python| ✅ | ✅ | ✅ | No | No | ✅ | ✅\n",
    "**HarmonyPy** | Python* | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | No\n",
    "**OpenDAP** | ✅ | ✅ | No | ✅ | ✅ | No | No |  ✅ \n",
    "**cmr-stac** | Python | ✅ | ✅ |✅ | No | No | No |  ✅ \n",
    "**Earthdata Portal** | ✅ | ✅ | ✅| No | No | No | ✅ |  ✅ \n",
    "**GDAL** | ✅* | ✅ | ✅ |✅ | No | ✅* | ✅* |  ✅ \n",
    "**rsat** | R | ✅ | No |✅ | No | ✅* | ✅* |  No\n",
    "**getSpatialData** | R | ✅ | No |✅ | No | ✅* | ✅* |  No\n",
    "\n",
    ": Earthdata Access Comparison {tbl-colwidths=\"[50,50]\"}\n",
    "\n",
    "\n",
    "### Installing earthdata with conda/mamba\n",
    "\n",
    "```bash\n",
    "conda -c conda-forge install earthdata\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7372e6-4495-4191-a377-dbcee15065f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NASA EDL and the Auth class\n",
    "\n",
    "What is Earthdata Login (EDL)?\n",
    "\n",
    "Earthdata Login provides free and immediate access to thousands of EOSDIS data products covering all Earth science disciplines and topic areas for researchers, applied science users, application developers, and the general public. For more information about Earthdata Login benefits, features, and terms of service, go to What do I need to know about Earthdata Login.To learn more about EOSDIS and its mission to meet the needs of diverse users, please visit our [Earthdata Website](https://urs.earthdata.nasa.gov/documentation/for_users/welcome).\n",
    "\n",
    "\n",
    "The `Auth` class will handle authentication with NASA Earthdata for both on-prem or cloud-hosted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb1926-3442-446a-8a35-fcbba8868d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the classes from earthdata\n",
    "from earthdata import Auth, DataCollections, DataGranules, Store\n",
    "\n",
    "auth = Auth()\n",
    "\n",
    "# First we try to use a .netrc, if it's not present we use the interactive login\n",
    "if not auth.login(strategy=\"netrc\"):\n",
    "    auth.login(strategy=\"interactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aed5ed-1f7b-46ac-b076-3278b5bc20cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. **Querying for data collections** (datasets)\n",
    "\n",
    "The DataCollection client can query CMR for any collection using all of CMR's Query parameters and has built-in accessors for the common ones. This makes it ideal for one liners and easier search notation.\n",
    "\n",
    "> Note: use bbox finder to get bounding box coordinates of an area of interest, [bboxfinder](http://bboxfinder.com/#0.000000,0.000000,0.000000,0.000000)\n",
    "\n",
    "**[CMR API Documentation](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5bf4c9-571b-4c93-af94-e66bd51cb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# We can now search for collections using a pythonic API client for CMR.\n",
    "\n",
    "# CollectionQuery = DataCollections().keyword('elevation change').bounding_box(-134.7,58.9,-133.9,59.2).temporal(\"2016-01-01\", \"2020-12-12\")\n",
    "\n",
    "CollectionQuery = DataCollections().parameters(\n",
    "    keyword = 'earth wind fire',\n",
    "    bounding_box = (-134.7,58.9,-133.9,59.2),\n",
    "    temporal = (\"2016-01-01\", \"2020-12-12\")\n",
    ")\n",
    "\n",
    "print(f'Collections found: {CollectionQuery.hits()}')\n",
    "\n",
    "# filtering what UMM fields to print using display(), meta is always included\n",
    "collections = CollectionQuery.fields(['ShortName', 'Abstract', 'Version']).get(5)\n",
    "# Inspect 5 results printing just the ShortName and Abstract\n",
    "for collection in collections:\n",
    "    # print(collection[\"meta\"][\"concept-id\"])\n",
    "    print(collection.concept_id(), collection.version())\n",
    "    # pprint(collection)\n",
    "    # display(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d45a6f-ac37-4744-bcfe-88ac3dd6ac07",
   "metadata": {},
   "source": [
    "The DataCollections class returns python dictionaries with some handy methods.\n",
    "\n",
    "```python \n",
    "collection.concept_id() # returns the concept-id, used to search for data granules\n",
    "collection.abstract() # returns the abstract\n",
    "collection.landing_page() # returns the landing page if present in the UMM fields\n",
    "collection.get_data() # returns the portal where data can be accessed.\n",
    "```\n",
    "\n",
    "The same results can be obtained using the `dict` syntax:\n",
    "\n",
    "```python\n",
    "collection[\"meta\"][\"concept-id\"] # concept-id\n",
    "collection[\"umm\"][\"RelatedUrls\"] # URLs, with GET DATA, LANDING PAGE etc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63792353-ab3e-4f0b-963d-7750e4b89113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want cloud collections\n",
    "CollectionQuery = DataCollections().daac(\"PODAAC\").cloud_hosted(True)\n",
    "\n",
    "print(f'Collections found: {CollectionQuery.hits()}')\n",
    "collections = CollectionQuery.fields(['ShortName']).get(10)\n",
    "# Printing 3 collections\n",
    "collections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5a34a-e808-4cc9-b34d-353d091a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the concept-id for the first 10 collections\n",
    "[collection.concept_id() for collection in collections]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99261da4-653c-413c-87cf-598a2c45bef7",
   "metadata": {},
   "source": [
    "### Cloud or On-prem with a simple parameter\n",
    "\n",
    "* `cloud_hosted(True)` will return cloud collections\n",
    "* `cloud_hosted(False)` will return on-prem collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb234815-8ce2-4255-a735-21218512557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ShortName = \"SMAP_JPL_L3_SSS_CAP_8DAY-RUNNINGMEAN_V5\"\n",
    "\n",
    "collections = DataCollections().short_name(ShortName).cloud_hosted(True).get()\n",
    "\n",
    "for collection in collections:\n",
    "    concept_id = collection.concept_id()\n",
    "    print(concept_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9c3bb-ac8b-48e8-8233-8c44da8fb7bc",
   "metadata": {},
   "source": [
    "## 2. **Querying for data granules**\n",
    "\n",
    "The DataGranules class provides similar functionality as the collection class. To query for granules in a more reliable way concept-id would be the main key.\n",
    "You can search data granules using a short name but that could (more likely will) return different versions of the same data granules. \n",
    "\n",
    "In this example we're querying for 20 data grnaules from ICESat-2  [ATL05](https://nsidc.org/data/ATL03/versions/) version `005` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364d737-5a79-4089-853f-76d2ad1c85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally speaking we won't need the auth instance for queries to collections and granules\n",
    "# Query = DataGranules().short_name('ATL03').version(\"005\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "\n",
    "GranuleQuery = DataGranules().parameters(\n",
    "    short_name = \"ATL03\",\n",
    "    version = \"005\",\n",
    "    bounding_box = (-134.7,58.9,-133.9,59.2),\n",
    "    # day_night_flag = \"day\",\n",
    "    # cloud_cover = (0,25),\n",
    "    # instrument = \"MODIS\",\n",
    "    # platform = \"TERRA\"\n",
    ")\n",
    "\n",
    "granules = GranuleQuery.get(3)\n",
    "\n",
    "for granule in granules:\n",
    "    # print(granule)\n",
    "    # pprint(granule)\n",
    "    display(granule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c90c43-6e17-42f5-8bf5-95fdd3cb0dce",
   "metadata": {},
   "source": [
    "## 3. **Accessing the data**\n",
    "\n",
    "With `earthdata` a researcher can get the files regardless if they are on-prem or cloud based with the same API call, although an important consideration is that if we want to access data in the cloud we must run the code in the cloud. This is because some S3 buckets are configured to only allow direct access (s3:// links) if the requester is in the same zone, `us-west-2`.\n",
    "\n",
    "### **On-prem access**  📡\n",
    "\n",
    "DAAC hosted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e4b90-f0e0-42e5-a4e2-d5444089161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2208422957-POCLOUD, cloud hosted\n",
    "\n",
    "cloud_collection = \"C2208422957-POCLOUD\"\n",
    "onprem_collection = \"C1972955240-PODAAC\"\n",
    "\n",
    "# The store class will get us the granules from their location\n",
    "store = Store(auth) \n",
    "\n",
    "GranuleQuery = DataGranules().concept_id(onprem_collection).bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {GranuleQuery.hits()}\")\n",
    "# getting more than 6,000 metadata records for demo purposes is going to slow us down a bit so let's get only 100\n",
    "onprem_granules = GranuleQuery.get(10)\n",
    "# Does this granule belong to a cloud-based collection?\n",
    "onprem_granules[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434466a3-602b-4dff-a260-f7db6901514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# accessing the data on prem means downloading it if we are in a local environment or \"uploading them\" if we are in the cloud.\n",
    "files = store.get(onprem_granules[0:3], \"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe45fff-68ea-4f01-94c7-416d79cfd84c",
   "metadata": {},
   "source": [
    "### **Cloud access** ☁️\n",
    "\n",
    "Same API, just a different place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44403d51-0aa3-423c-8fff-e40d4969aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GranuleQuery = DataGranules().concept_id(cloud_collection).bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {GranuleQuery.hits()}\")\n",
    "cloud_granules = GranuleQuery.get(10)\n",
    "# is this a cloud hosted data granule?\n",
    "cloud_granules[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd11cf5-8a6a-452d-a124-99a022298dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# accessing the data on prem means downloading it if we are in a local environment or \"uploading them\" if we are in the cloud.\n",
    "files = store.get(cloud_granules[0:3], \"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564b3c2-00ad-473f-b5f8-3fdaa77ee09f",
   "metadata": {},
   "source": [
    "### ☁️ **Cloud Access Part II: Opening files with S3FS**\n",
    "\n",
    "Being in the cloud allows us to stream data as if we were using it locally. Pairing gridded datasets on S3 and xarray isa very useful patter when we deal with a lot of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142739a4-409a-4d98-8978-43aa221b09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_links = cloud_granules[0].data_links(s3_only=True)\n",
    "https_links = []\n",
    "s3_links = []\n",
    "\n",
    "# TODO: earthdata should be able to infer the provider based on URL, \n",
    "# it does it when we use the DataGranules but not with plain URLs\n",
    "fs = Store(auth).get_s3fs_session('POCLOUD')\n",
    "\n",
    "for granule in cloud_granules[0:10]:\n",
    "    https_links.append(granule.data_links()[0])\n",
    "    s3_links.append(granule.data_links(s3_only=True)[0])\n",
    "\n",
    "fileset = [fs.open(s3_granule)for s3_granule in s3_links[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b47fc5-1756-4600-9c74-e1290f904c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "lonrange = [-160, -130]\n",
    "latrange = [68, 80]\n",
    "\n",
    "ds_smap_L3 = xr.open_mfdataset(\n",
    "    fileset,\n",
    "    combine='nested',\n",
    "    concat_dim='time',\n",
    "    decode_cf=True,\n",
    "    coords='minimal',\n",
    "    chunks={'time': 1}\n",
    "    ).sel(longitude=slice(lonrange[0],lonrange[1]), latitude=slice(latrange[1],latrange[0]))\n",
    "ds_smap_L3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276eca3-ca27-4970-9367-7e65e5f2302f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recap\n",
    "\n",
    "**Wait, we said 4 lines of Python**\n",
    "\n",
    "```python\n",
    "\n",
    "from earthdata import Auth, DataGranules, Store\n",
    "auth = Auth().login(strategy=\"netrc\")\n",
    "granules = DataGranules().concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2).get()\n",
    "files = Store(auth).get(granules, local_path='./data')\n",
    "\n",
    "# Now to the important science!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779e877-2f0c-4da2-92d5-6cc299204956",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Related links\n",
    "\n",
    "**CMR** API documentation: https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html\n",
    "\n",
    "**EDL** API documentation: https://urs.earthdata.nasa.gov/\n",
    "\n",
    "NASA OpenScapes: https://nasa-openscapes.github.io/earthdata-cloud-cookbook/\n",
    "\n",
    "Github repository: https://github.com/nsidc/earthdata\n",
    "\n",
    "\n",
    "Contact: luis.lopez@nsidc.org\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
