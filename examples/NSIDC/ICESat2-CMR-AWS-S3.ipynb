{
 "cells": [
  {
   "cell_type": "raw",
   "id": "593945ff-19b1-4313-9d70-0a9fdae03b96",
   "metadata": {},
   "source": [
    "---\n",
    "title: Accessing NSIDC Cloud Collections Using CMR\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-wallace",
   "metadata": {},
   "source": [
    "Programmatic access of NSIDC data can happen in 2 ways:\n",
    "\n",
    "```text\n",
    "Search -> Download -> Process -> Research\n",
    "```\n",
    "\n",
    "<img src=\"img/download-model.png\" width=\"35%\"/>\n",
    "\n",
    "```text\n",
    "Search -> Process in the cloud -> Research\n",
    "```\n",
    "\n",
    "<img src=\"img/cloud-model.png\" width=\"35%\"/>\n",
    "\n",
    "> **Credit**: Open Architecture for scalable cloud-based data analytics. From Abernathey, Ryan (2020): Data Access Modes in Science.\n",
    "\n",
    "\n",
    "## The big picture: \n",
    "\n",
    "There is nothing wrong with downloading data to our local machine but that can get complicated or even impossible if a dataset is too large.\n",
    "For this reason NSIDC along with other NASA data centers started to collocate or migrate their dataset holdings to the cloud. \n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Authenticate with the NASA Earthdata Login API (EDL).\n",
    "2. Search granules/collections using a CMR client that supports authentication\n",
    "3. Parse CMR responses and get AWS S3 URLs\n",
    "4. Access the data granules using temporary AWS credentials given by the NSIDC cloud credentials endpoint\n",
    "\n",
    "### Data used:\n",
    "\n",
    "*  ICESat-2 [ATL03](https://nsidc.org/data/ATL03/versions/4): This data set contains height above the WGS 84 ellipsoid (ITRF2014 reference frame), latitude, longitude, and time for all photons.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "* [NASA Eartdata Login (EDL) credentials](https://urs.earthdata.nasa.gov/)\n",
    "* python libraries:\n",
    "  - h5py\n",
    "  - matplotlib\n",
    "  - xarray\n",
    "  - s3fs\n",
    "  - [python-cmr](https://github.com/nasa/eo-metadata-tools/tree/master/CMR/python)\n",
    "    - cmr helpers: included in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-indian",
   "metadata": {},
   "source": [
    "## Querying CMR for NSIDC data in the cloud\n",
    "\n",
    "Most collections at NSIDC have not being migrated to the cloud and can be found using CMR with no authentication at all. Here is a simple example for \n",
    "altimeter data (ATL03) coming from the ICESat-2 mission. First we'll search the regular collection and then we'll do the same using the cloud collection.\n",
    "\n",
    "**Note**: This notebook uses CMR to search and locate the data granules, this is not the only workflow for data access and discovery. \n",
    "\n",
    "* **HarmonyPy**: Uses **Harmony** the NASA API to search, subset and transform the data in the cloud.\n",
    "* **cmr-stac**: A \"static\" metadata catalog than can be read by **Intake** oand other client libraries to optimize the access of files in the cloud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-malawi",
   "metadata": {},
   "source": [
    "## Cloud Collections\n",
    "\n",
    "Some NSIDC cloud collections are not yet, which means that temporarily you'll have to request access emailing nsidc@nsidc.org so your Eartdata login is in the authorized list for early users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import textwrap\n",
    "\n",
    "from cmr.search import collection as cmr_collection\n",
    "from cmr.search import granule \n",
    "from cmr.auth import token\n",
    "\n",
    "from cmr_auth import CMRAuth\n",
    "\n",
    "# NON_AWS collections are hosted at the NSIDC DAAC data center\n",
    "# AWS_CLOUD collections are hosted at AWS S3 us-west-2\n",
    "NSIDC_PROVIDERS = {\n",
    "    'NSIDC_HOSTED': 'NSIDC_ECS', \n",
    "    'AWS_HOSTED':'NSIDC_CPRD'\n",
    "}\n",
    "\n",
    "# Use your own EDL username\n",
    "USER = 'betolink'\n",
    "\n",
    "print('Enter your NASA Earthdata login password:')\n",
    "password = getpass.getpass()\n",
    "# This helper class will handle credentials with CMR\n",
    "CMR_auth = CMRAuth(USER, password)\n",
    "# Token to search preliminary collections on CMR\n",
    "cmr_token = CMR_auth.get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The query object uses a simple python dictionary\n",
    "query = {'short_name':'ATL03',\n",
    "         'token': cmr_token,\n",
    "         'provider': NSIDC_PROVIDERS['AWS_HOSTED']}\n",
    "\n",
    "collections = cmr_collection.search(query)\n",
    "\n",
    "for collection in collections[0:3]:\n",
    "    wrapped_abstract = '\\n'.join(textwrap.wrap(f\"Abstract: {collection['umm']['Abstract']}\", 80)) + '\\n'\n",
    "    print(f\"concept-id: {collection['meta']['concept-id']}\\n\" +\n",
    "          f\"Title: {collection['umm']['EntryTitle']}\\n\" +\n",
    "          wrapped_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4366b-5f99-419c-8e6c-6e56ef95e2f4",
   "metadata": {},
   "source": [
    "## Searching for data granules in the cloud with CMR\n",
    "\n",
    "CMR uses different collection id's for datasets in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the concept-id for our ATL03 in the cloud we do the same thing we did with ATL03 hosted at\n",
    "from cmr_serializer import QueryResult\n",
    "# NSIDC but using the cloud concept-id\n",
    "# Jeneau ice sheet\n",
    "query = {'concept-id': 'C2027878642-NSIDC_CPRD',\n",
    "         'token': cmr_token,\n",
    "         'bounding_box': '-135.1977,58.3325,-133.3410,58.9839'}\n",
    "\n",
    "# Querying for ATL03 v3 using its concept-id and a bounding box\n",
    "results = granule.search(query, limit=1000)\n",
    "granules = QueryResult(results).items()\n",
    "\n",
    "print(f\"Total granules found: {len(results)} \\n\")\n",
    "\n",
    "# Print the first 3 granules\n",
    "for g in granules[0:3]:\n",
    "    display(g)\n",
    "    # You can use: print(g) for the regular text representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961fbdf-b472-4ac7-98e6-519c5b3b56f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**NOTE**: Not all the data granules for NSIDC datasets have been migrated to S3. This might result in different counts between the NSIDC hosted data collections and the ones in AWS S3\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c566fc2-ff42-46c5-ae63-f584c1aa706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can list the s3 links but \n",
    "for g in granules:\n",
    "    for link in g.data_links():\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-vitamin",
   "metadata": {},
   "source": [
    "We note that our RelatedLinks array now contain links to AWS S3, these are the direct URIs for our data granules in the AWS us-west-2 region. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-handle",
   "metadata": {},
   "source": [
    "## Data Access using AWS S3\n",
    "\n",
    "* **IMPORTANT**: This section will only work if this notebook is running on the AWS **us-west-2** zone\n",
    "\n",
    "There is more than one way of accessing data on AWS S3, either downloading it to your local machine using the official client library or using a python library. \n",
    "\n",
    "**Performance tip**: using the HTTPS URLs will decrease the access performance since these links have to internally be processed by AWS's content delivery system (CloudFront). To get a better performance we should access the `S3://` URLs with BOTO3 or a high level S3 enabled library (i.e. S3FS)\n",
    "\n",
    "\n",
    "Related links:\n",
    "* [HDF in the Cloud challenges and solutions for scientific data](http://matthewrocklin.com/blog/work/2018/02/06/hdf-in-the-cloud)\n",
    "* [Cloud Storage (Amazon S3) HDF5 Connector](https://www.hdfgroup.org/solutions/enterprise-support/cloud-amazon-s3-storage-hdf5-connector/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c175b0f-cc33-4302-bce1-886943ebff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import h5py\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ only temporary credentials\n",
    "# This credentials only last 1 hour.\n",
    "s3_cred = CMR_auth.get_s3_credentials()\n",
    "\n",
    "s3_fs = s3fs.S3FileSystem(key=s3_cred['accessKeyId'],\n",
    "                          secret=s3_cred['secretAccessKey'],\n",
    "                          token=s3_cred['sessionToken'])\n",
    "\n",
    "# Now you could grab S3 links to your cloud instance (EC2, Hub etc) using:\n",
    "# s3_fs.get('s3://SOME_LOCATION/ATL03_20181015124359_02580106_004_01.h5', 'test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29b8c4-f876-4d8f-8fc2-3e00fc83cafb",
   "metadata": {},
   "source": [
    "Now that we have the propper credentials in our file mapper, we can access the data within AWS us-west-2.\n",
    "\n",
    "If we are not running this notebook in **`us-west-2`** will get an **`access denied`** error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-valuation",
   "metadata": {},
   "source": [
    "## Using xarray to open files on S3\n",
    "\n",
    "ATL data is complex so xarray doesn't know how to extract the important bits out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "with s3_fs.open('s3://nsidc-cumulus-prod-protected/ATLAS/ATL03/004/2018/10/15/ATL03_20181015124359_02580106_004_01.h5', 'rb') as s3f:\n",
    "    with h5py.File(s3f, 'r') as f:\n",
    "        print([key for key in f.keys()])\n",
    "        gt1l = xr.Dataset({'height': (['x'], f['gt1l']['heights']['h_ph'][:]),\n",
    "                       'latitude': (['x'], f['gt1l']['heights']['lat_ph'][:]), \n",
    "                       'longitude': (['x'], f['gt1l']['heights']['lon_ph'][:]),\n",
    "                       'dist_ph': (['x'], f['gt1l']['heights']['dist_ph_along'][:])})\n",
    "gt1l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7c108-d545-4270-9f12-0396ff28fbf5",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c009d66-564c-4024-b583-742072709a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt1l.height.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434e087-d870-484f-b512-dd7d15fef64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "gt1l.height.plot(ax=ax, ls='', marker='o', ms=1)\n",
    "gt1l.height.rolling(x=1000, min_periods=500, center=True).mean().plot(ax=ax, c='k', lw=2)\n",
    "ax.set_xlabel('Along track distance (m)', fontsize=12);\n",
    "ax.set_ylabel('Photon Height (m)', fontsize=12)\n",
    "ax.set_title('ICESat-2 ATL03', fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "subax = fig.add_axes([0.69,0.50,0.3,0.3], projection=ccrs.NorthPolarStereo())\n",
    "subax.set_aspect('equal')\n",
    "subax.set_extent([-180., 180., 30, 90.], ccrs.PlateCarree())\n",
    "subax.add_feature(cfeature.LAND)\n",
    "subax.plot(gt1l.longitude, gt1l.latitude, transform=ccrs.PlateCarree(), lw=1);\n",
    "\n",
    "fig.savefig('test.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
