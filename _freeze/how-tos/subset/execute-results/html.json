{
  "hash": "0f14e627cd4ad11fc3bb94221703b9b5",
  "result": {
    "markdown": "---\ntitle: How do I subset data granules?\nexecute:\n  eval: false\n---\n\n\n## How do I subset a data granule using Harmony?\n\n::: {.panel-tabset group=\"language\"}\n\n## Python\n\nInstall the [harmony-py](\"https://github.com/nasa/harmony-py\") package:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Install harmony-py\npip install -U harmony-py\n```\n:::\n\n\nImport packages: \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport datetime as dt\n\nfrom harmony import BBox, Client, Collection, Request, LinkType\n\nimport s3fs\nimport xarray as xr\n```\n:::\n\n\n### Set up Harmony client and authentication\n\nWe will authenticate the following Harmony request using a netrc file. See the [appendix](\"https://nasa-openscapes.github.io/earthdata-cloud-cookbook/appendix/authentication.html\") for more information on [Earthdata Login](\"https://urs.earthdata.nasa.gov/\") and netrc setup. This basic line below to create a Harmony Client assumes that we have a .netrc available.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nharmony_client = Client()\n```\n:::\n\n### Create and submit Harmony request\n\nWe are interested in the [GHRSST Level 4 MUR Global Foundation Sea Surface Temperature Analysis dataset](https://doi.org/10.5067/GHGMR-4FJ04). We are subsetting over the Pacific Ocean to the west of Mexico during 1:00 - 2:00 on 10 March 2021. The dataset is organized into daily files, so while we are specifying a single hour in our request, this will return that full day's worth of data. \n\n\n::: {.cell}\n\n```{.python .cell-code}\ndataset_short_name = 'MUR-JPL-L4-GLOB-v4.1'\n\nrequest = Request(\n  collection=Collection(id=dataset_short_name),\n  spatial=BBox(-125.469,15.820,-99.453,35.859),\n  temporal={\n    'start': dt.datetime(2021, 3, 10, 1),\n    'stop': dt.datetime(2021, 3, 10, 2)\n  }\n)\n\njob_id = harmony_client.submit(request)\n\nharmony_client.wait_for_processing(job_id)\n```\n:::\n\n### Open and read the subsetted file in `xarray`\n\nHarmony data outputs can be accessed within the cloud using the s3 URLs and AWS credentials provided in the Harmony job response. Using `aws_credentials` we can retrieve the credentials needed to access the Harmony s3 staging bucket and its contents. We then use the AWS `s3fs` package to create a file system that can then be read by xarray.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresults = harmony_client.result_urls(job_id, link_type=LinkType.s3)\nurls = list(results)\nurl = urls[0]\n\ncreds = harmony_client.aws_credentials()\n\ns3_fs = s3fs.S3FileSystem(\n    key=creds['aws_access_key_id'],\n    secret=creds['aws_secret_access_key'],\n    token=creds['aws_session_token'],\n    client_kwargs={'region_name':'us-west-2'},\n)\n\nf = s3_fs.open(url, mode='rb')\nds = xr.open_dataset(f)\nds\n```\n:::\n\n### Plot data\n\nUse the xarray built in plotting function to create a simple plot along the x and y dimensions of the dataset:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nds.analysed_sst.plot() ;\n```\n:::\n\n\n## R\n\nR code coming soon!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Coming soon!\n```\n:::\n\n\n## Matlab\n\nMatlab code coming soon!\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Coming soon!\n```\n:::\n\n\n## Command Line\n\nWith `wget` and `curl`:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Coming soon!\n```\n:::\n\n\n\n\n:::\n\n## How do I subset an OPeNDAP granule in the cloud?\n\n\n## How do I subset a data granule using xarray?\n\n\n## How do I download a subset of NetCDF-4?\n*this might be a deprecated idea*",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}