{
  "hash": "cededa3e0023855573eeb7ac48ee0bf5",
  "result": {
    "markdown": "---\ntitle: \"Access NetCDF-4/HDF5 Data \"\nexecute:\n  eval: false\n  echo: fenced\n---\n\n\n## Introduction\n\nWe can access HDF5 or NetCDF-4 data directly from NASA Earthdata Cloud using the following code.\n\n## Code\n\nHere are our recommended approaches for accessing NetCDF-4/HDF5 data in NASA Earthdata Cloud with code.\n\n::: {.panel-tabset group=\"language\"}\n## Python\n\nWe will access land ice height from ATLAS/ICESat-2 V005 (10.5067/ATLAS/ATL06.005). The data are provided as HDF5 granules (files) that span about 1/14th of an orbit.\n\nWe will access a single HDF5 file from inside the AWS cloud (us-west-2 region, specifically) and load it into Python as an `xarray` `dataset`. This approach leverages S3 native protocols for efficient access to the data.\n\nIn Python we can use the [`earthdata`](https://earthdata.readthedocs.io/en/latest/) library (to be renamed `earthaccess` very soon!)\n\nTo install the package we'll run this code from the command line. Note: you can run shell code directly from a Jupyter Notebook cell by adding a `!`: `!conda install`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{bash}}\n# Install earthdata\nconda install -c conda-forge earthdata\n```\n````\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{python}}\n## Import earthdata\nfrom earthdata import Auth, Store, DataGranules, DataCollections\nimport xarray as xr\n```\n````\n:::\n\n\n### Earthdata Login Authentication\n\nAn Earthdata Login account is required to access data from the NASA Earthdata system. Thus, to access NASA data, you need Earthdata Login. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.\n\nWe will authenticate below using a netrc file. See the (TBD) appendix for more information on netrc setup.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{python}}\nauth = Auth().login(strategy=\"netrc\")\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\n# The Store class will let us download data from NASA directly\nstore = Store(auth)\n```\n````\n:::\n\n\n### Working with the URLs directly\nIf we choose, we can use `earthaccess` to grab the file's URLs and then access them with another library. Getting the links to our data is quiet simple with the `data_links()` method on each of the results. See the previous Find Data How-To for more information on how to discover datasets of interest. \n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{python}}\n# Searching over western Greenland coast over two weeks in July 2022\ngranules = DataGranules().concept_id(\"C2153572614-NSIDC_CPRD\").temporal(\"2022-07-17\",\"2022-07-31\").bounding_box(-51.96423,68.10554,-48.71969,70.70529).get()\nprint(len(granules))\ns3_url = granules[0].data_links(access=\"direct\")\nds = xr.open_dataset(store.open(s3_url))\nds\n```\n````\n:::\n\n### TODO: This produces the following error: \"Credentials for the cloud provider None are not available\" - need to fix this!\n\n## R\n\nR code coming soon!\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# Coming soon!\n```\n````\n:::\n\n\n## Matlab\n\nMatlab code coming soon!\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Coming soon!\n```\n:::\n\n\n## Command Line\n\nWith `wget` and `curl`:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{bash}}\n# Coming soon!\n```\n````\n:::\n\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}